<html>
<head>
<meta name="description" content="James Hazelden">
<link rel=StyleSheet href="nut_styles.css" type="text/css" media=all>
<title>James Hazelden</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<link rel="icon" href="./koch-snowflake.png" type="image/x-icon">
<script language="JavaScript">
<!--
   if (self.location.href != top.location.href) {
      top.location.href = self.location.href;
   }
-->
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
</head>
<body>

<div class="main_text">
<h1>Loss Landscapes Emerging from BNNs</h1>
<hr>

<ol style="max-width:45%;">
    <li> <a href="#intro">Introduction</a> 
    <li> <a href="#simple">Most Simple Case</a> 
    <ol>
        <li> <a href="#loss_simple">Loss Landscape</a></li> 
        <li> <a href="#gradients_simple">Gradient Descent on This Landscape</a></li> 
    </ol>
    <li> <a href="#signal">Signal Processing Approaches</a>
    <ol>
    </ol>
    <li> <a href="#refs">Useful References</a>
</ol>
<br>

<h2 id="intro">Introduction</h2>
<p>
My research is currently focused on training network of biological neurons (BNNs) on machine learning (ML) tasks. In <a href="./bnns_spiking_data.html">another post</a>, I dive into a specific task well suited for BNNs: training BNNs on spiking data. In that work, I encountered a number of issues. One issue was designing a clear loss reflecting the desired solution of the BNN. I found that the <a href="#loss_landscape_def">loss landscape*</a> exhibited discontinuities and very chaotic gradients at the micro scale but had structure at the macro scale. This blog post focuses on analyzing loss landscapes for some simple examples with the aim of building up some understanding and proposing solutions to facilitate training in such contexts.
</p>

<br>

<p style="font-size: 0.55cm;"><u id="loss_landscape_def">* The loss landscape</u> is a surface of losses on a subset of the data resulting from small perturbations in network parameters. For example, if the network, \(N_w\), just has one parameter, \(w\), then the loss landscape is the set \(\{\text{loss}(N_{w'}(X),Y^*) | w - \delta w \leq w' \leq w + \delta w\},\) where \(\delta w\) is specified and \(X, Y^*\) are the inputs and targets, respectively, for the subset of samples.
</p>


<h2 id="simple">Most Simple Case</h2>
<p>
The simplest case I considered here was simply turning a single <a href="https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model">Hodgkin-Huxley</a> (HH) neuron off, so that it does not spike anymore. Let \(\eta = (V, m, n, h)\) denote the neuron state which is composed of voltage and gating variables. If \(a(t)\) is the output of the neuron at time \(t\), then we can let the loss just be the average output over some time interval \(\tau\):
$$L(\eta) = \frac{1}{\tau} \int_0^\tau a(t) dt.$$
Ultimately, we aim to minimize \(L\), meaning that the neuron outputs as little as possible.
</p>

<h2 id="loss_simple">Loss Landscape</h2> 
<p>

First, let's generate the loss landscape by running a single neuron trial with a time interval \(\tau = 1\) second, and evaluating the final loss. Varying the single weight parameter \(w\) gives the following results, where blue denotes loss and orange denotes number of firings:
<img src="./simple_no_grad.png" style="max-width:80%; width:60%;" alt="Full Single Trial"/>
Note that around \(w = 1.8\) is where the neuron undergoes a bifurcation and the behavior changes, leading to no firing. This is due to the fact that a neuron can only fire so many times within a given interval. 
</p>
<p>
We can also look at a subset of the plot for more clear detail. Here is a zoom in on the range \(w \in [0.5, 0.75]\):
<img src="./simple_no_grad_0.5_0.75.png" style="max-width:80%; width:60%;" alt="Zoom Single Trial"/>
</p>
<br>
<p>
These plots demonstrate some key problems with the task and performing gradient descent. In particular, the zoom in shows that the loss changes chaotically on the micro scale and any approximate gradients would have to be almost infinite to approximate these changes. Furthermore, there are large discontinuous jumps in the loss when a the number of firings changes. Regarding the former problem, it might seem that we can increase the resolution very high so that the micro changes are more smooth. However, increasing the resolution cannot fix the latter problem because changes in firing still cause discontinuous jumps no matter what the resolution because this is an integer valued discontinuous function itself.
</p>
<p>
At this point, the goal may seem hopeless. How can we get gradients from something so chaotic? Let's understand what is causing the issues. Note that we are using a fixed timeframe \(\tau\) which may not be sufficiently long. Even worse, we are only using a single neuron to evaluate the loss curve. If we let \(N_{trials}\) denote the number of neurons we use to sample the loss, in the limit \(\tau, N_{trials} \rightarrow \infty\) the big varied jumps in the loss curve should go away. So, let's add noise to each neuron (with fixed initial conditions for now) and increase \(N_{trials}\). If we let \(N_{trials} = 10\), below is the resulting loss curve:
</p>
<img src="./simple_0_2_10_trials.png" style="max-width:80%; width:60%;" alt="Full Single Trial"/>
<p>
As can be seen, the discontinuities are much less extreme. Let's also zoom in as we did above:
</p>
<img src="./simple_0.5_0.75_10_trials.png" style="max-width:80%; width:60%;" alt="Full Single Trial"/>
<p>
Wow! A curve that previously looked like a discontinuous mess now appears to be almost completely straight! This makes sense because each of the 10 trial neurons fires at different times and so the effects of firings are much less abrupt for a single trial. We can still see some high frequency noise in the curve but otherwise it looks much better.
</p>

<h2 id="gradients_simple">Gradient Descent on This Landscape</h2>

<h3>Approximate Approach</h3>

<p>
The next step in analysis of this very simple case is actually trying out gradient descent as an optimization method. Firstly, let's try a finite difference approach based on the precomputed loss curve. Suppose we are given the loss curve as a set:
$$\{(w_i, L(w_i)) | w_{i+1} = w_i + \Delta w, i=1...n\}.$$
Instead of automatically differentiating to compute gradients of \(L\) with respect to \(w\), we can just use a centered difference approximation:
$$\frac{\partial L}{\partial w_i} \approx \frac{L(w_{i+1}) - L(w_{i-1})}{2 \Delta w}.$$
We can then use this approximate derivative to do a gradient descent step:
$$w \mapsto w - \eta \frac{\partial L}{\partial w}.$$
Finally, since we are operating on the set of points \(w_i\), we can round to the nearest gridpoint (which should not be a big change with a high resolution grid). 
</p>
<p>
Let's see what happens with varied initial values of \(w\) and learning rates \(\eta\). First, below is a plot with initial \(w = 1.5, \eta = 0.1\):
<img src="./approx_grad_descent_1.5_0.1.png" style="max-width:50%; width:50%;" alt="Grad Approx 1"/>
Note that the gradient descent gets "stuck" because it keeps jumping between two values. Here is the same case but with \(\eta = 0.2\):
<img src="./approx_grad_descent_1.5_0.2.png" style="max-width:50%; width:50%;" alt="Grad Approx 2"/>
In this case, one of the approximate gradients is simple 0 (i.e. the curve is flat at this point) so it gets stuck again. 
</p>
<p>
Things are not looking that good. The issue is that at the micro scale there is a lot of noise in the curve even though it posses a tangent that is quite clear without the noise. This suggests a possible fix: <i>let's try using multiple sample points to compute the approximate tangent</i>. To do so, we can select points locally to the left and right of the sample point then use a linear regression fit to approximate the tangent. Here is an example of such fitting at a point on the loss plot with 5 neighbors sampled to both the left and right:
<img src="./idea.png" style="max-width:50%; width:50%;" alt="Idea"/>
</p>
<p>
If we use an adaptive value of \(\eta\) that grows over learning (so that we don't get stuck as above) and the linear regression approach with 10 local neighbors, we get convergence:
<img src="./approx_grad_descent_1.5_0.05_True.png" style="max-width:50%; width:50%;" alt="Grad Approx Linear Regression"/>
</p>

<h3>Automatic Approach</h3>
<p>text here</p>

<h3>Molification</h3>

<p>
One possible avenue for generating loss landscapes that are more easy to do gradient descent on is "molification." Molification is the application of a "molifier" to a badly behaving function (e.g. very jagged with discontinuities) through an operation such as convolution. A molifier is defined by the following criteria:
</p>

<br>
<center style="font-size: 0.6cm;">
$$\text{Definition (molifier): } \phi \text{ is a smooth function on } \mathbb{R}^n \text{ satisfying: }$$
1. <a href="https://en.wikipedia.org/wiki/Support_(mathematics)">Compact support</a>, which essentially just guarantees that is is only locally applied, 
$$2. \int_{\mathbb{R}^n} \phi(x) dx = 1, \text{ so it is like a distribution and it does not change scaling when we convolve it,}$$
$$3. \lim_{\epsilon \rightarrow 0} \epsilon^{-n} \phi(x/\epsilon) = \delta(x) \text{ (dirac delta function)}.$$
</center>
<br>

<p>
I intuitively think of the final criteria as requiring that the function "looks like" a discontinuous jump at the \(n\)th derivative scale. Here is an example of a function undergoing progressive molification from Wikipedia (which, incidentally, I think they used ray-tracing to produce):
</p>
<br>
<img src="https://upload.wikimedia.org/wikipedia/commons/a/a9/Heat_eqn.gif" alt="Molificiation" style="width:40%;"/>
<br>
<p>
The canonical molifier is the bump function \(\phi(x)\) on \(\mathbb{R}^n\) defined by 
$$ \phi(x) = \begin{cases} k_n e^{\frac{1}{|x|^2 - 1}} & |x| \lt 1 \\ 0 & |x| \geq 1 \end{cases},$$
where \(k_n\) is chosen to be one over the volume so that condition (2) above is satisfied:
</p>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Mollifier_Illustration.svg/1920px-Mollifier_Illustration.svg.png" alt="Bump 1d"/>
<p>
Note that is might be tempting to use a function like a Gaussian blob as a molifier, but such a function is not compactly supported even though is gets very small as we let \(x\) grow. 
</p>

<h3>Applying to BNN loss</h3>

<p> 
There are two conceivable ways of applying molification to our task. Firstly, we can simply apply molification to the final loss function. This has a more straight-forward effect on the loss but it has the disadvantage of requiring us to compute all losses in a local neighborhood to perform molification at one point. Secondly, we could apply molification over time to the voltage trace outputted from a particular neuron. The idea with this is to "smooth" out the spikes leading to better gradients and is very related to the <a href="https://arxiv.org/pdf/1901.09948.pdf">surrogate-gradients</a> approach. The main difference is that in these approaches they are working with discontinuous neurons (leaky-integrate-and-fire) and most of the papers I have seen using this approach make LIFT neurons continuous by completely disregarding gradients when spikes occur. 
</p>

<h3>Approach 1: Molifying Loss</h3>

<p>TODO: Explore</p>
<img src="./losses_molified.png" alt="Loss Molified" style="width:50%;"/>

<h3>Approach 2: Molifying Voltage</h3>

<p>Here is a raster plot of 1000 neuron voltages with random noise and no transient and with the same input weight</p>

<img src="./voltages_imshow.png" alt="Voltages Raster"/>

<p>Here are some examples of these voltage traces:</p>

<img src="./voltages_example.png" alt="Voltages"/>

<p>
Let's try molifying the voltages. First, let \(t_0\) denote the time of the first spike occurence for the first voltage trace above. Let's zoom in around \(t_0\) for this voltage:
</p>

<img src="./voltage_zoom.png" alt="Voltage Zoom"/>

<p>
Here is a molifier using the scaled bump from above, where \(c\) is chosen to be some small value \(\lt \delta\) in the figure above:
</p>

<img src="./molifier_voltage.png" alt="Voltage Molifier"/>
<img src="./molified_voltage.png" alt="Voltage Molified"/>

<h3 id="signal">Signal Processing Approach</h3>

<p>
This research is very open and I am considering a number of approaches. One that seems like a promising approach is using signal processing methods for training BNNs. This section will explore this.
</p>

<h4>Cross-Correlation</h4>

<p>
For real or complex functions \(f, g\) on some domain \(D\), their cross-correlation is defined as:
$$(f \star g)(\tau) := \int_D \overline{f(t)} g(t + \tau) dt = \int_D \overline{f(t - \tau)} g(t) dt,$$
where \(\overline{f}\) is the complex conjugate and \(\tau\) is called the "lag". To understand this definition, if \(g(t)\) is a discrete signal and is just \(f(t)\) but shifted to the right by \(\tau\), then \(f \star g\) will be zero everywhere except at \(\tau = 1\), where it will be the integral of \(|f(t)|^2\), which is the squared <a href="https://mathworld.wolfram.com/L2-Norm.html">L^2 norm</a> of \(f(t)\). Note that if \(g, f\) are not signals and are continuously varying, then the cross-correlation will not be zero outside but will decay outside 1 and have a max at 1.
</p>

<p>
Cross-correlation loss:
$$\text{Loss} = \int_0^T y(t) y^*(t + \tau) dt.$$
</p>

<h3 id="refs">Useful References</h3>
<ol>
    <li><a href="https://arxiv.org/pdf/1706.04698.pdf">Gradient Descent for Spiking Neural Networks</a></li>
    <li><a href="https://arxiv.org/pdf/1901.09948.pdf">Surrogate Gradient Learning in Spiking Neural Networks</a></li>
    <li><a href="https://nowak.ece.wisc.edu/ece830/ece830_spring13_adaptive_filtering.pdf">Adaptive Filtering</a></li>
</ol>






<!--<img src="./voltage.png" style="max-width:100%; width:100%;" alt="Voltage"/>-->


<div class="top_bar" style="left: 30px;">
<a href="index.html" style="text-decoration: none;">goto: main</a>
</div>

<div class="top_bar" style="right: 30px;">
<a href="" style="text-decoration: none;">goto: top</a>
</div>

</body>
</html>
